{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment Design"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table of Contents\n",
    "* [Concepts of Experiment Design](#Concepts)\n",
    "* [Statistical Considerations in Testing](#Statistical-Consideration)\n",
    "* [A/B Test Case Study](#A/B-Test-Case-Study)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concepts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](img/img1.png \"confounding effect\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* In the right plot on the above picture, we see that the price of Apple has very strong positive correlation with number of lawyers in New York. Does that mean price apple drives increase in number of laywers or the other way around? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image.png](img/img2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The answer is `No`. Strong correlation might be due to coincidence and there are other true underlying factors. In this case, Apple price and number of lawyers in NY are driven by steadiy increase in inflation rate and population in NY respectively. There exists confounders.\n",
    "* **Correlation does not mean causation!!**\n",
    "* **A well-designed controlled experiement is needed to deduce causality**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Types of Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* [Observational Study](#Observational-Study)\n",
    "* [Designed Experiemnt](#Designed-Experiment)\n",
    "* [Quasi Experiment](#Quasi-Experiment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image.png](img/img3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observational Study\n",
    "* observational study is defined by a **lack of control**, also known as correlational studies. No control is exerted on the variable interest, perhaps due to **ethical concerns** or a **lack of power to enact the manipulation**. For instance, in medical studies, if we want to study the effect of smoking on health, it would be unethical to force people into smoking behavior. Conclusion needs to be drawn by comparing existing smoking and non-smoking groups.\n",
    "\n",
    "* Causaulity generally **cannot** be drawn from observational studies, due to potential existence of confounders. However, interesting observational study results could spark ideas for additional testings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Designed Experiment\n",
    "* Comparison between two groups while controling for other factors. For instance, testing if layout of a button causes more visitors to click on it. **Equivalence** between groups is usually carried out by **randomization** procedure. A **unit of analysis** is the entity under study, like a page view or a web user. Randomly assign users into test/control groups allows similar distribution. E.g. Complete random sampling, stratified sampling\n",
    "\n",
    "#### Quasi Experiment\n",
    "* In between a designed experiment and observational study is a quasi experiment. For instance, rolling out a new website interface to all users to see how much time they spend on it might be considered a quasi. The are no multiple groups to compare. However, pre-change and post-change behaviors can still be compared. However, there might be other reason for the change, users might gravitated to higher usage regardless of change in user interface.\n",
    "\n",
    "* Another example is test some new supplemental materials for high school course. Select two schools, one with new materials and one without. This is considered quasi since selection of two schools cannot be conisdered random.\n",
    "\n",
    "* While quasi cannot provide the same strength in causality inference as true experiment. It still **provides strong evidence** for relationship being invesitaged. This is especially true if **matching** is performed to **identify similar groups**. Another advantage is that **ease to setup** and **more flexibility**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `between-subject design`: a/b test, difference between groups(control/test) are compared, random\n",
    "* `within-subject design`: repeated measure, by measuring an individual's output in all conditions, we can account for individuals' inclination. E.g. Have a individual rates all three different color palette for a single product, we can know if one palette is particularly better than the other two. Sometimes it might not be possible to conduct within subject design. For intance, one a shopper finishes buying a product, he might not comes back to try out a new design.\n",
    "* **Note**: `Factorial Design` manipulate multiple features of interest, instead of having just two groups, we could have *control*, *x_only*, *y_only*, *x_and_y* groups. However, this method is most frequently seen in engineerning and physical sciences domain and less seen in social and medical realms, where individual differences can impede experiment results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Types of sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `simple random sampling`: each individual in the population has equal chance of being selected. **Cons**: certain groups might be underrepresented, especially those with a low proportion \n",
    "\n",
    "* `stratified random sampling`: performs simple random sampling on each disjoint groups\n",
    "    * `proportional sampling`: guarantees certain level of knowledge from each subset\n",
    "    * `non-proportional sampling`: draws same number of samples from each group regardless of their proportion, requires weighting each group seperately"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Measure Outcomes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The goal of the study is not the same as **evaluation metrics**\n",
    "* For instance, \n",
    "    * `goal`: improve test score, `metric`: confidence going into a test, as a proxy for test score if the latter cannot be obtained directly or in a timely manner\n",
    "    * `goal`: improve user satisfaction, `metric`: survey rating from a scale of 1 - 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Funnels\n",
    "A funnel is the flow of steps in the entire website browsing experience. Typically, funnels ends at where your main evaluation metric is recorded, and includes a step where experimental manipulation can be performed.\n",
    "\n",
    "For instance, the following is a common funnel,\n",
    "* Visit the site homepage\n",
    "* Search for a desired product or click on a product category\n",
    "* Click on a product image\n",
    "* Add the product to the cart\n",
    "* Check out and purchase\n",
    "\n",
    "It is worth noting that the funnel flow might be idealized compared to actual user practice. Users might perform multiple searches and purchase many items in a single session. A user might access the site through external links and subverting thet top part of the funnel. **Refining the funnel and being specific about the kinds of events that are expected help to create a consistent reliable design and analysis**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Unit of Diversion\n",
    "Once is funnel is established, think about where to implement experimental manipulation. If the **goal** is to **change the way the website looks after a user clicks on the product page**. We need to think about split the users into groups. The place to assign user into test/control is call **unit of diversion**.\n",
    "\n",
    "* `Event-based` (e.g. pageview): Each time a user loads up the page of interest, the experimental condition is randomly rolled. **Cons**: ignores previous visits, could lead to inconsistent experience, if the condition causes a user-visble change.\n",
    "* `Cookie-based`: A cookie is unique to a device, however, it could be subverted through anonymous browsing or a user clearing out cookies.\n",
    "* `Account-based` (e.g. Userid): Reliable, but requires user to have accounts and logged in. Pool of data might be limited since large proportion of website traffic do not have accounts.\n",
    "\n",
    "**Note**: When selecting unit of diversion, consistent experience is an important factor to consider. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Invariant and Evaluation Metrics\n",
    "* `Evaluation Metric`: We want to see a difference in groups to measure if mmanipulation is success. For instance, increased click-through-rate from search results to products or increase in overall revenue. \n",
    "* `Invariant Metric`: Metrics that do not vary between groups. Used to check that the experiment is running as expected. For example, in experiment with cookie-based diversion, the number of cookies in each group would be a invariant metric. Another metric could compare the **distribution of time in which cookie is generated**, to check bias in randomization process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Controling Variables\n",
    "In order to determine causality between two features, we need to control for two things. 1. Manipulate the feature of interest. 2. All other features are accounted for\n",
    "\n",
    "If we do not control all features or there is lack of equivalence between groups, we may be susceptible to **confounding variables**. Correlation observed might be due to changes in a third variable, rather than on causing the other"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checking Validity\n",
    "* `Construct Validity`: Check if the goal of study is **aligned** with the evaluation metric\n",
    "* `Internal Validity`: Refers to the degree to which a causal relationship can be derived from an experiments' result. **Controling and accounting for other variables** is **key** to maintain good internal validity\n",
    "* `External Validity`: The ability of experimental outcome to be **generalized to a broader population**. Sampling problem: how representative in the sample to the population?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checking Bias\n",
    "* `Sampling Bias`: Sampling bias are those cause our observations to not be representative of the population. For exmaple, having assignment done in a arbitrary fashio instead of random assignment or matched groups. \n",
    "    * `Self-selection bias`: types of people that respond to a survey might be **qualitatively different** from those who do not\n",
    "    * `survivor bias`: deals with missing value, when losses or dropout of observed units is not accounted for. \n",
    "* `Novelty Bias`: causes observer to change behavior simply because something is new. We might not be able to gauge the true effect of change until after the novelty effect wears off. This will be important for cases where we **track changes over time**, such as trying to get users to re-visit a webpage or use an app more frequently. Perhaps **not a concern** for one-shot effect.\n",
    "* `Order Bias`: Especially relevant to within-subject experiments. A easy get around is to **randomize the order of conditions**.\n",
    "    * `Primary effect`: affects **early** conditions, perhaps biasing them to be recalled better or serve as anchor values for later conditions\n",
    "    * `Recency effect`: affect **later** conditions, due to fresher in memory or task fatigue\n",
    "* `Experimenter Bias`: This is where the presence or knowledge of the experimenter can affect participants' behavior. If an experimenter **knows** what the condition a participant is in, they might subtly **nudge the participant towards their expeced result**.\n",
    "    * `Blinding`: The administrator of a procedure or the participant do not know the condition being used, to avoid subconcious bias. **Double blind** design hides conditions from both administrator and particpants"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ethics in Experimentation\n",
    "* `Minimize Participant Risk`\n",
    "* `Have clear benefits for risk taken`\n",
    "* `Provide informed consent`\n",
    "* `Handle sensitive data appropriately`: Collected data should be **anonymized** as much as possible; surveys and census results are often also **aggregated** to avoid tracing outcomes back to any one person."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SMART Mnmonic for Experiment Design\n",
    "* **S**pecific: Make sure the goals of your experiment are specific.\n",
    "* **M**easurable: Outcomes must be measurable using objective metrics\n",
    "* **A**chievable: The steps taken for the experiment and the goals must be realistic.\n",
    "* **R**elevant: The experiment needs to have purpose behind it.\n",
    "* **T**imely: Results must be obtainable in a reasonable time frame.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to top](#Experiment-Design)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
